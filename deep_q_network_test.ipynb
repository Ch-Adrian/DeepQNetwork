{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dm-tree dm-sonnet tensorflow tensorflow_datasets ipywidgets matplotlib >/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.experimental import jax2tf\n",
    "import sonnet as snt\n",
    "import tensorflow as tf\n",
    "import treeimport os\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from functools import partial\n",
    "\n",
    "import chex\n",
    "import haiku as hk\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.experimental import jax2tf\n",
    "import sonnet as snt\n",
    "import tensorflow as tf\n",
    "import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "  net = hk.nets.MLP([300, 100, 10])\n",
    "  return net(x)\n",
    "\n",
    "f = hk.transform(f)\n",
    "\n",
    "rng = jax.random.PRNGKey(42)\n",
    "x = jnp.ones([1, 28 * 28 * 1])\n",
    "params = f.init(rng, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_variable(path, value):\n",
    "  name = '/'.join(map(str, path)).replace('~', '_')\n",
    "  return tf.Variable(value, name=name)\n",
    "\n",
    "class JaxModule(snt.Module):\n",
    "  def __init__(self, params, apply_fn, name=None):\n",
    "    super().__init__(name=name)\n",
    "    self._params = tree.map_structure_with_path(create_variable, params)\n",
    "    self._apply = jax2tf.convert(lambda p, x: apply_fn(p, None, x))\n",
    "    self._apply = tf.autograph.experimental.do_not_convert(self._apply)\n",
    "\n",
    "  def __call__(self, inputs):\n",
    "    return self._apply(self._params, inputs)\n",
    "\n",
    "net = JaxModule(params, f.apply)\n",
    "[v.name for v in net.trainable_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds_train, ds_test = tfds.load('mnist', split=('train', 'test'), shuffle_files=True, as_supervised=True)\n",
    "\n",
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  image = tf.cast(image, tf.float32) / 255.\n",
    "  return image, label\n",
    "\n",
    "ds_train = ds_train.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(60000)\n",
    "ds_train = ds_train.batch(100)\n",
    "ds_train = ds_train.repeat()\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.batch(100)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = JaxModule(params, f.apply)\n",
    "opt = snt.optimizers.Adam(1e-3)\n",
    "\n",
    "@tf.function(experimental_compile=True, autograph=False)\n",
    "def train_step(images, labels):\n",
    "  \"\"\"Performs one optimizer step on a single mini-batch.\"\"\"\n",
    "  with tf.GradientTape() as tape:\n",
    "    images = snt.flatten(images)\n",
    "    logits = net(images)\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,\n",
    "                                                          labels=labels)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    params = tape.watched_variables()\n",
    "    loss += 1e-4 * sum(map(tf.nn.l2_loss, params))\n",
    "\n",
    "  grads = tape.gradient(loss, params)\n",
    "  opt.apply(grads, params)\n",
    "  return loss\n",
    "\n",
    "for step, (images, labels) in enumerate(ds_train.take(6001)):\n",
    "  loss = train_step(images, labels)\n",
    "  if step % 1000 == 0:\n",
    "    print(f\"Step {step}: {loss.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model):\n",
    "  total = 0\n",
    "  correct = 0\n",
    "  for images, labels in ds_test:\n",
    "    predictions = tf.argmax(model(snt.flatten(images)), axis=1)\n",
    "    correct += tf.math.count_nonzero(tf.equal(predictions, labels))\n",
    "    total += images.shape[0]\n",
    "\n",
    "  print(\"Got %d/%d (%.02f%%) correct\" % (correct, total, correct / total * 100.))\n",
    "\n",
    "accuracy(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sample(correct, rows, cols):\n",
    "  \"\"\"Utility function to show a sample of images.\"\"\"\n",
    "  n = 0\n",
    "\n",
    "  f, ax = plt.subplots(rows, cols)\n",
    "  if rows > 1:\n",
    "    ax = tf.nest.flatten([tuple(ax[i]) for i in range(rows)])\n",
    "  f.set_figwidth(14)\n",
    "  f.set_figheight(4 * rows)\n",
    "\n",
    "  for images, labels in ds_test:\n",
    "    predictions = tf.argmax(net(snt.flatten(images)), axis=1)\n",
    "    eq = tf.equal(predictions, labels)\n",
    "    for i, x in enumerate(eq):\n",
    "      if x.numpy() == correct:\n",
    "        label = labels[i]\n",
    "        prediction = predictions[i]\n",
    "        image = tf.squeeze(images[i])\n",
    "\n",
    "        ax[n].imshow(image)\n",
    "        ax[n].set_title(\"Prediction:{}\\nActual:{}\".format(prediction, label))\n",
    "\n",
    "        n += 1\n",
    "        if n == (rows * cols):\n",
    "          break\n",
    "\n",
    "    if n == (rows * cols):\n",
    "      break\n",
    "\n",
    "sample(correct=True, rows=1, cols=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample(correct=False, rows=2, cols=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
